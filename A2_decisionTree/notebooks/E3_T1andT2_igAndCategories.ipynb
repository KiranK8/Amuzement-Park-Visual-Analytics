{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42005509",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4159743141.py, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 62\u001b[1;36m\u001b[0m\n\u001b[1;33m    print('IG for %s %.6f' % (var, IG(df,'split')), 'group2: {\"else\"}', 'group1:', leftChild)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# %load C:\\Users\\pandh\\Desktop\\Assignments\\Visual Analytics\\Assignment_2\\template\\A2_decisionTree\\scripts\\E3_T1andT2_igAndCategories.py\n",
    "\n",
    "\"\"\"Code for exercise 3, task 1 and task 2.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# scikit-learn for decision tree classification and evaluation\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# load the data and make a copy with numerical entries only\n",
    "df = pd.read_csv('../data/adult.csv', na_values='?').dropna()\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "datasetnum = df.copy()\n",
    "datasetnum.drop(['education'], axis=1, inplace=True)\n",
    "\n",
    "for i in list(datasetnum):\n",
    "    if not (datasetnum[i].dtype == np.float64 or datasetnum[i].dtype == np.int64):\n",
    "        datasetnum[i] = datasetnum[i].astype('category')\n",
    "        datasetnum[i] = datasetnum[i].cat.codes\n",
    "\n",
    "\n",
    "def IG(df, var):\n",
    "    \"\"\"\n",
    "    Compute information gain for a given dataframe w.r.t. income \n",
    "    when splitting into categorical variable var.\n",
    "    \n",
    "    Return:\n",
    "        float: information gain\n",
    "    \"\"\"\n",
    "    # entropy before split\n",
    "    entropy1 = df.income.value_counts(normalize=True).\\\n",
    "        apply(lambda x: -x*np.log2(x)).groupby(level=0).sum().sum()\n",
    "    \n",
    "    # entropy after split\n",
    "    entropy = df.groupby([var]).income.value_counts(normalize=True).\\\n",
    "        apply(lambda x: -x*np.log2(x)).groupby(level=0).sum()\n",
    "    weights = df[var].value_counts(normalize=True)\n",
    "    entropy2 = entropy = (entropy*weights).sum()\n",
    "    \n",
    "    # return information gain\n",
    "    return entropy1 - entropy2\n",
    "\n",
    "\n",
    "var = 'race' # TODO edit here according to findings\n",
    "\n",
    "# compute the information gain for one variable\n",
    "print('Information gain for', var, IG(df, var), '\\n')\n",
    "\n",
    "# list all categories of a categorical variable\n",
    "print(df[var].astype('category').cat.categories, '\\n')\n",
    "\n",
    "# TODO compute the information gain for your own splits\n",
    "# all levels that are listed are in group, all others in the other\n",
    "leftChild = ['Black', 'White']\n",
    "df['split'] = df[var].apply(lambda x: x in leftChild)\n",
    " print('IG for %s %.6f' % (var, IG(df,'split')), 'group2: {\"else\"}', 'group1:', leftChild)\n",
    "df.drop(['split'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# apply the sorting to the dataframe\n",
    "dfSorted = df.copy()\n",
    "dfSorted.drop(['education'], axis=1, inplace=True)\n",
    "\n",
    "for i in list(dfSorted):\n",
    "    if not (dfSorted[i].dtype == np.float64 or dfSorted[i].dtype == np.int64):\n",
    "        # define a specific order for race\n",
    "        if var in i: # TODO Adapt\n",
    "            catType = CategoricalDtype(categories=[\n",
    "                'Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'\n",
    "                ], ordered=True)\n",
    "            dfSorted[i] = dfSorted[i].astype(catType)\n",
    "        else:\n",
    "            dfSorted[i] = dfSorted[i].astype('category')\n",
    "        dfSorted[i] = dfSorted[i].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc01d5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "772f203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\pandh\\anaconda3\\lib\\site-packages (0.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b30b333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for all categorical variables:\n",
      "\n",
      "Information gain for race 0.008294113320606256\n",
      "Index(['Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'], dtype='object')\n",
      "IG for custom split in race: 0.000230 group2: {\"else\"} group1: ['Black', 'White']\n",
      "Sorted DataFrame Example for 'race':\n",
      "   age  workclass  education-num  marital-status  occupation  relationship  \\\n",
      "0   39          5             13               4           0             1   \n",
      "1   50          4             13               2           3             0   \n",
      "2   38          2              9               0           5             1   \n",
      "3   53          2              7               2           5             0   \n",
      "4   28          2             13               2           9             5   \n",
      "\n",
      "   race  sex  capital-gain  capital-loss  hour-per-week  native-country  \\\n",
      "0     4    1          2174             0             40              38   \n",
      "1     4    1             0             0             13              38   \n",
      "2     4    1             0             0             40              38   \n",
      "3     2    1             0             0             40              38   \n",
      "4     2    0             0             0             40               4   \n",
      "\n",
      "   income  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Code for exercise 3, task 1 and task 2.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# graphviz for tree drawing\n",
    "import graphviz\n",
    "\n",
    "# scikit-learn for decision tree classification and evaluation\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data and make a copy with numerical entries only\n",
    "df = pd.read_csv('../data/adult.csv', na_values='?').dropna()\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "# Ensure 'income' is a categorical variable for our analysis\n",
    "df['income'] = df['income'].astype('category')\n",
    "\n",
    "# Convert other categorical variables to codes for numeric processing\n",
    "datasetnum = df.copy()\n",
    "datasetnum.drop(['education'], axis=1, inplace=True)\n",
    "\n",
    "for i in list(datasetnum):\n",
    "    if not (datasetnum[i].dtype == np.float64 or datasetnum[i].dtype == np.int64):\n",
    "        datasetnum[i] = datasetnum[i].astype('category')\n",
    "        datasetnum[i] = datasetnum[i].cat.codes\n",
    "\n",
    "def IG(df, var):\n",
    "    \"\"\"\n",
    "    Compute information gain for a given dataframe w.r.t. income \n",
    "    when splitting into categorical variable var.\n",
    "    \n",
    "    Return:\n",
    "        float: information gain\n",
    "    \"\"\"\n",
    "    # Entropy before split\n",
    "    entropy1 = df.income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).sum()\n",
    "    \n",
    "    # Entropy after split\n",
    "    entropy = df.groupby([var]).income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).groupby(level=0).sum()\n",
    "    weights = df[var].value_counts(normalize=True)\n",
    "    entropy2 = (entropy * weights).sum()\n",
    "    \n",
    "    # Return information gain\n",
    "    return entropy1 - entropy2\n",
    "\n",
    "# List all categorical variables (excluding 'income')\n",
    "categorical_vars = df.select_dtypes(include=['category']).columns.tolist()\n",
    "categorical_vars.remove('income')\n",
    "\n",
    "# Compute and print the information gain for all categorical variables\n",
    "print(\"Information Gain for all categorical variables:\")\n",
    "for var in categorical_vars:\n",
    "    ig = IG(df, var)\n",
    "    print(f\"Information gain for {var}: {ig:.6f}\")\n",
    "\n",
    "# Example specific computation for 'race' (already included in the loop above)\n",
    "var = 'race'\n",
    "\n",
    "# Compute the information gain for one variable 'race'\n",
    "print('\\nInformation gain for', var, IG(df, var))\n",
    "\n",
    "# List all categories of the 'race' variable\n",
    "print(df[var].astype('category').cat.categories)\n",
    "\n",
    "# Example of computing the information gain for a custom split in 'race'\n",
    "leftChild = ['Black', 'White']\n",
    "df['split'] = df[var].apply(lambda x: x in leftChild)\n",
    "print('IG for custom split in %s: %.6f' % (var, IG(df, 'split')), 'group2: {\"else\"}', 'group1:', leftChild)\n",
    "df.drop(['split'], axis=1, inplace=True)\n",
    "\n",
    "# Apply specific sorting to the dataframe for the 'race' variable\n",
    "dfSorted = df.copy()\n",
    "dfSorted.drop(['education'], axis=1, inplace=True)\n",
    "\n",
    "for i in list(dfSorted):\n",
    "    if not (dfSorted[i].dtype == np.float64 or dfSorted[i].dtype == np.int64):\n",
    "        # Define a specific order for 'race'\n",
    "        if var in i:\n",
    "            catType = CategoricalDtype(categories=[\n",
    "                'Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'\n",
    "            ], ordered=True)\n",
    "            dfSorted[i] = dfSorted[i].astype(catType)\n",
    "        else:\n",
    "            dfSorted[i] = dfSorted[i].astype('category')\n",
    "        dfSorted[i] = dfSorted[i].cat.codes\n",
    "\n",
    "print(\"Sorted DataFrame Example for 'race':\")\n",
    "print(dfSorted.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf96fc",
   "metadata": {},
   "source": [
    "## Task 2 (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eb622d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Information Gain for different orderings of 'race' categories:\n",
      "\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'White', 'Other') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Other', 'Black', 'White') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Other', 'White', 'Black') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'White', 'Black', 'Other') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'White', 'Other', 'Black') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Black', 'Asian-Pac-Islander', 'Other', 'White') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Black', 'Asian-Pac-Islander', 'White', 'Other') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Black', 'Other', 'Asian-Pac-Islander', 'White') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Black', 'Other', 'White', 'Asian-Pac-Islander') -> Information Gain: 0.008294\n",
      "\n",
      "Best ordering based on information gain: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White')\n",
      "\n",
      "Training accuracy with best ordering: 0.98\n",
      "Cross-validation accuracy: 0.81 (+/- 0.01)\n",
      "\n",
      "Classification report for the decision tree with best ordering:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     22654\n",
      "           1       0.98      0.92      0.95      7508\n",
      "\n",
      "    accuracy                           0.98     30162\n",
      "   macro avg       0.98      0.96      0.97     30162\n",
      "weighted avg       0.98      0.98      0.97     30162\n",
      "\n",
      "\n",
      "Features used by the decision tree:\n",
      "Index(['age', 'workclass', 'education', 'education-num', 'marital-status',\n",
      "       'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n",
      "       'capital-loss', 'hour-per-week', 'native-country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Improved Sorting of Categorical Variables\n",
    "\n",
    "# Select 'race' variable for reordering analysis\n",
    "variable_to_reorder = 'race'\n",
    "\n",
    "# List all categories of the selected variable\n",
    "categories = df[variable_to_reorder].astype('category').cat.categories.tolist()\n",
    "\n",
    "# Generate a subset of possible permutations of the categories for simplicity\n",
    "orderings = list(permutations(categories))[:10]  # Limit to first 10 permutations for simplicity\n",
    "\n",
    "print(f\"\\nInformation Gain for different orderings of '{variable_to_reorder}' categories:\\n\")\n",
    "\n",
    "# Compute information gain for each ordering\n",
    "ig_scores = []\n",
    "for ordering in orderings:\n",
    "    # Define the category type with the current ordering\n",
    "    catType = CategoricalDtype(categories=ordering, ordered=True)\n",
    "    df_sorted = df.copy()\n",
    "    df_sorted[variable_to_reorder] = df_sorted[variable_to_reorder].astype(catType)\n",
    "    df_sorted[variable_to_reorder] = df_sorted[variable_to_reorder].cat.codes\n",
    "    \n",
    "    # Ensure all categorical variables are converted to numerical codes\n",
    "    for col in df_sorted.select_dtypes(include=['category', 'object']).columns:\n",
    "        df_sorted[col] = df_sorted[col].astype('category').cat.codes\n",
    "    \n",
    "    # Compute the information gain with the reordered categories\n",
    "    ig = IG(df_sorted, variable_to_reorder)\n",
    "    ig_scores.append(ig)\n",
    "    print(f\"Ordering: {ordering} -> Information Gain: {ig:.6f}\")\n",
    "\n",
    "# Find the best ordering based on the highest information gain\n",
    "best_ordering_index = np.argmax(ig_scores)\n",
    "best_ordering = orderings[best_ordering_index]\n",
    "\n",
    "print(f\"\\nBest ordering based on information gain: {best_ordering}\")\n",
    "\n",
    "# Apply the best ordering to the original dataframe\n",
    "catType_best = CategoricalDtype(categories=best_ordering, ordered=True)\n",
    "df_best_ordered = df.copy()\n",
    "df_best_ordered[variable_to_reorder] = df_best_ordered[variable_to_reorder].astype(catType_best)\n",
    "df_best_ordered[variable_to_reorder] = df_best_ordered[variable_to_reorder].cat.codes\n",
    "\n",
    "# Ensure all categorical variables are converted to numerical codes in the best ordered dataframe\n",
    "for col in df_best_ordered.select_dtypes(include=['category', 'object']).columns:\n",
    "    df_best_ordered[col] = df_best_ordered[col].astype('category').cat.codes\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_best_ordered.drop('income', axis=1)\n",
    "y = df_best_ordered['income']\n",
    "\n",
    "# Train the decision tree with the best ordering\n",
    "clf_best = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_best.fit(X, y)\n",
    "\n",
    "# Evaluate the decision tree\n",
    "train_accuracy = accuracy_score(y, clf_best.predict(X))\n",
    "print(f\"\\nTraining accuracy with best ordering: {train_accuracy:.2f}\")\n",
    "\n",
    "# Cross-validation to evaluate the decision tree's performance\n",
    "cv_scores = cross_val_score(clf_best, X, y, cv=10)\n",
    "print(f\"Cross-validation accuracy: {cv_scores.mean():.2f} (+/- {cv_scores.std() * 2:.2f})\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification report for the decision tree with best ordering:\")\n",
    "print(classification_report(y, clf_best.predict(X)))\n",
    "\n",
    "# Check the features used by the decision tree\n",
    "features_used = X.columns[clf_best.feature_importances_ > 0]\n",
    "print(\"\\nFeatures used by the decision tree:\")\n",
    "print(features_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6519f98a",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2 (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ac40c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New dataset with reordered categories saved as 'adult_reordered.csv' in the 'data' directory.\n"
     ]
    }
   ],
   "source": [
    "# Best Category Order\n",
    "\n",
    "# Create a new DataFrame to store the reordered dataset\n",
    "df_reordered = df.copy()\n",
    "\n",
    "# Apply the best ordering to the 'race' variable in the new DataFrame\n",
    "df_reordered[variable_to_reorder] = df_reordered[variable_to_reorder].astype(CategoricalDtype(categories=best_ordering, ordered=True))\n",
    "df_reordered[variable_to_reorder] = df_reordered[variable_to_reorder].cat.codes\n",
    "\n",
    "# Ensure all categorical variables are converted to numerical codes in the reordered dataset\n",
    "for col in df_reordered.select_dtypes(include=['category', 'object']).columns:\n",
    "    df_reordered[col] = df_reordered[col].astype('category').cat.codes\n",
    "\n",
    "# Save the new dataset to a CSV file\n",
    "df_reordered.to_csv('../data/adult_reordered.csv', index=False)\n",
    "\n",
    "# Print a message to confirm the dataset has been created and saved\n",
    "print(f\"\\nNew dataset with reordered categories saved as 'adult_reordered.csv' in the 'data' directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53861ffb",
   "metadata": {},
   "source": [
    "## Task 2 (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4b321b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy with reordered dataset: 0.98\n",
      "Cross-validation accuracy for reordered dataset: 0.81 (+/- 0.01)\n",
      "\n",
      "Classification report for the decision tree with reordered dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     22654\n",
      "           1       0.98      0.92      0.95      7508\n",
      "\n",
      "    accuracy                           0.98     30162\n",
      "   macro avg       0.98      0.96      0.97     30162\n",
      "weighted avg       0.98      0.98      0.97     30162\n",
      "\n",
      "\n",
      "Training accuracy with original dataset: 0.98\n",
      "Cross-validation accuracy for original dataset: 0.81 (+/- 0.01)\n",
      "\n",
      "Classification report for the decision tree with original dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     22654\n",
      "           1       0.98      0.92      0.95      7508\n",
      "\n",
      "    accuracy                           0.98     30162\n",
      "   macro avg       0.98      0.96      0.97     30162\n",
      "weighted avg       0.98      0.98      0.97     30162\n",
      "\n",
      "\n",
      "Comparison between original and reordered datasets:\n",
      "Training accuracy - Original: 0.98, Reordered: 0.98\n",
      "Cross-validation accuracy - Original: 0.81 (+/- 0.01), Reordered: 0.81 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "# Recompute the classification report for the new dataset with reordered categories\n",
    "\n",
    "# Load the new dataset with reordered categories\n",
    "df_reordered = pd.read_csv('../data/adult_reordered.csv')\n",
    "\n",
    "# Separate the features and target variable for the reordered dataset\n",
    "X_reordered = df_reordered.drop('income', axis=1)\n",
    "y_reordered = df_reordered['income']\n",
    "\n",
    "# Train a new decision tree on the reordered dataset\n",
    "clf_reordered = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_reordered.fit(X_reordered, y_reordered)\n",
    "\n",
    "# Compute the training accuracy for the reordered dataset\n",
    "train_accuracy_reordered = accuracy_score(y_reordered, clf_reordered.predict(X_reordered))\n",
    "print(f\"\\nTraining accuracy with reordered dataset: {train_accuracy_reordered:.2f}\")\n",
    "\n",
    "# Perform cross-validation on the reordered dataset\n",
    "cv_scores_reordered = cross_val_score(clf_reordered, X_reordered, y_reordered, cv=10)\n",
    "print(f\"Cross-validation accuracy for reordered dataset: {cv_scores_reordered.mean():.2f} (+/- {cv_scores_reordered.std() * 2:.2f})\")\n",
    "\n",
    "# Generate the classification report for the reordered dataset\n",
    "print(\"\\nClassification report for the decision tree with reordered dataset:\")\n",
    "classification_report_reordered = classification_report(y_reordered, clf_reordered.predict(X_reordered))\n",
    "print(classification_report_reordered)\n",
    "\n",
    "# Convert all categorical variables in the original dataset to numerical codes\n",
    "df_encoded = df.copy()\n",
    "for col in df_encoded.select_dtypes(include=['category', 'object']).columns:\n",
    "    df_encoded[col] = df_encoded[col].astype('category').cat.codes\n",
    "\n",
    "# Separate the features and target variable for the original dataset\n",
    "X_original = df_encoded.drop('income', axis=1)\n",
    "y_original = df_encoded['income']\n",
    "\n",
    "# Train a new decision tree on the original dataset\n",
    "clf_original = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_original.fit(X_original, y_original)\n",
    "\n",
    "# Compute the training accuracy for the original dataset\n",
    "train_accuracy_original = accuracy_score(y_original, clf_original.predict(X_original))\n",
    "print(f\"\\nTraining accuracy with original dataset: {train_accuracy_original:.2f}\")\n",
    "\n",
    "# Perform cross-validation on the original dataset\n",
    "cv_scores_original = cross_val_score(clf_original, X_original, y_original, cv=10)\n",
    "print(f\"Cross-validation accuracy for original dataset: {cv_scores_original.mean():.2f} (+/- {cv_scores_original.std() * 2:.2f})\")\n",
    "\n",
    "# Generate the classification report for the original dataset\n",
    "print(\"\\nClassification report for the decision tree with original dataset:\")\n",
    "classification_report_original = classification_report(y_original, clf_original.predict(X_original))\n",
    "print(classification_report_original)\n",
    "\n",
    "# Compare the results\n",
    "print(\"\\nComparison between original and reordered datasets:\")\n",
    "print(f\"Training accuracy - Original: {train_accuracy_original:.2f}, Reordered: {train_accuracy_reordered:.2f}\")\n",
    "print(f\"Cross-validation accuracy - Original: {cv_scores_original.mean():.2f} (+/- {cv_scores_original.std() * 2:.2f}), Reordered: {cv_scores_reordered.mean():.2f} (+/- {cv_scores_reordered.std() * 2:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ba743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c01adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e0474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for all categorical variables:\n",
      "\n",
      "Information gain for race 0.008294113320606256\n",
      "Index(['Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'], dtype='object')\n",
      "IG for custom split in race: 0.000230 group2: {\"else\"} group1: ['Black', 'White']\n",
      "Sorted DataFrame Example for 'race':\n",
      "   age  workclass  education-num  marital-status  occupation  relationship  \\\n",
      "0   39          5             13               4           0             1   \n",
      "1   50          4             13               2           3             0   \n",
      "2   38          2              9               0           5             1   \n",
      "3   53          2              7               2           5             0   \n",
      "4   28          2             13               2           9             5   \n",
      "\n",
      "   race  sex  capital-gain  capital-loss  hour-per-week  native-country  \\\n",
      "0     4    1          2174             0             40              38   \n",
      "1     4    1             0             0             13              38   \n",
      "2     4    1             0             0             40              38   \n",
      "3     2    1             0             0             40              38   \n",
      "4     2    0             0             0             40               4   \n",
      "\n",
      "   income  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "\n",
      "Information Gain for different orderings of 'race' categories:\n",
      "\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'White', 'Other') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Other', 'Black', 'White') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Other', 'White', 'Black') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'White', 'Black', 'Other') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'White', 'Other', 'Black') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Black', 'Asian-Pac-Islander', 'Other', 'White') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Black', 'Asian-Pac-Islander', 'White', 'Other') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Black', 'Other', 'Asian-Pac-Islander', 'White') -> Information Gain: 0.008294\n",
      "Ordering: ('Amer-Indian-Eskimo', 'Black', 'Other', 'White', 'Asian-Pac-Islander') -> Information Gain: 0.008294\n",
      "\n",
      "Best ordering based on information gain: ('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White')\n",
      "\n",
      "Training accuracy with best ordering: 0.98\n",
      "Cross-validation accuracy: 0.81 (+/- 0.01)\n",
      "\n",
      "Classification report for the decision tree with best ordering:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     22654\n",
      "           1       0.98      0.92      0.95      7508\n",
      "\n",
      "    accuracy                           0.98     30162\n",
      "   macro avg       0.98      0.96      0.97     30162\n",
      "weighted avg       0.98      0.98      0.97     30162\n",
      "\n",
      "\n",
      "Features used by the decision tree:\n",
      "Index(['age', 'workclass', 'education', 'education-num', 'marital-status',\n",
      "       'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n",
      "       'capital-loss', 'hour-per-week', 'native-country'],\n",
      "      dtype='object')\n",
      "\n",
      "New dataset with reordered categories saved as 'adult_reordered.csv' in the 'data' directory.\n",
      "\n",
      "Training accuracy with reordered dataset: 0.98\n",
      "Cross-validation accuracy for reordered dataset: 0.81 (+/- 0.01)\n",
      "\n",
      "Classification report for the decision tree with reordered dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     22654\n",
      "           1       0.98      0.92      0.95      7508\n",
      "\n",
      "    accuracy                           0.98     30162\n",
      "   macro avg       0.98      0.96      0.97     30162\n",
      "weighted avg       0.98      0.98      0.97     30162\n",
      "\n",
      "\n",
      "Training accuracy with original dataset: 0.98\n",
      "Cross-validation accuracy for original dataset: 0.81 (+/- 0.01)\n",
      "\n",
      "Classification report for the decision tree with original dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     22654\n",
      "           1       0.98      0.92      0.95      7508\n",
      "\n",
      "    accuracy                           0.98     30162\n",
      "   macro avg       0.98      0.96      0.97     30162\n",
      "weighted avg       0.98      0.98      0.97     30162\n",
      "\n",
      "\n",
      "Comparison between original and reordered datasets:\n",
      "Training accuracy - Original: 0.98, Reordered: 0.98\n",
      "Cross-validation accuracy - Original: 0.81 (+/- 0.01), Reordered: 0.81 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Code for exercise 3, task 1 and task 2.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# graphviz for tree drawing\n",
    "import graphviz\n",
    "\n",
    "# scikit-learn for decision tree classification and evaluation\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data and make a copy with numerical entries only\n",
    "df = pd.read_csv('../data/adult.csv', na_values='?').dropna()\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "# Ensure 'income' is a categorical variable for our analysis\n",
    "df['income'] = df['income'].astype('category')\n",
    "\n",
    "# Convert other categorical variables to codes for numeric processing\n",
    "datasetnum = df.copy()\n",
    "datasetnum.drop(['education'], axis=1, inplace=True)\n",
    "\n",
    "for i in list(datasetnum):\n",
    "    if not (datasetnum[i].dtype == np.float64 or datasetnum[i].dtype == np.int64):\n",
    "        datasetnum[i] = datasetnum[i].astype('category')\n",
    "        datasetnum[i] = datasetnum[i].cat.codes\n",
    "\n",
    "def IG(df, var):\n",
    "    \"\"\"\n",
    "    Compute information gain for a given dataframe w.r.t. income \n",
    "    when splitting into categorical variable var.\n",
    "    \n",
    "    Return:\n",
    "        float: information gain\n",
    "    \"\"\"\n",
    "    # Entropy before split\n",
    "    entropy1 = df.income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).sum()\n",
    "    \n",
    "    # Entropy after split\n",
    "    entropy = df.groupby([var]).income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).groupby(level=0).sum()\n",
    "    weights = df[var].value_counts(normalize=True)\n",
    "    entropy2 = (entropy * weights).sum()\n",
    "    \n",
    "    # Return information gain\n",
    "    return entropy1 - entropy2\n",
    "\n",
    "# List all categorical variables (excluding 'income')\n",
    "categorical_vars = df.select_dtypes(include=['category']).columns.tolist()\n",
    "categorical_vars.remove('income')\n",
    "\n",
    "# Compute and print the information gain for all categorical variables\n",
    "print(\"Information Gain for all categorical variables:\")\n",
    "for var in categorical_vars:\n",
    "    ig = IG(df, var)\n",
    "    print(f\"Information gain for {var}: {ig:.6f}\")\n",
    "\n",
    "# Example specific computation for 'race' (already included in the loop above)\n",
    "var = 'race'\n",
    "\n",
    "# Compute the information gain for one variable 'race'\n",
    "print('\\nInformation gain for', var, IG(df, var))\n",
    "\n",
    "# List all categories of the 'race' variable\n",
    "print(df[var].astype('category').cat.categories)\n",
    "\n",
    "# Example of computing the information gain for a custom split in 'race'\n",
    "leftChild = ['Black', 'White']\n",
    "df['split'] = df[var].apply(lambda x: x in leftChild)\n",
    "print('IG for custom split in %s: %.6f' % (var, IG(df, 'split')), 'group2: {\"else\"}', 'group1:', leftChild)\n",
    "df.drop(['split'], axis=1, inplace=True)\n",
    "\n",
    "# Apply specific sorting to the dataframe for the 'race' variable\n",
    "dfSorted = df.copy()\n",
    "dfSorted.drop(['education'], axis=1, inplace=True)\n",
    "\n",
    "for i in list(dfSorted):\n",
    "    if not (dfSorted[i].dtype == np.float64 or dfSorted[i].dtype == np.int64):\n",
    "        # Define a specific order for 'race'\n",
    "        if var in i:\n",
    "            catType = CategoricalDtype(categories=[\n",
    "                'Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'\n",
    "            ], ordered=True)\n",
    "            dfSorted[i] = dfSorted[i].astype(catType)\n",
    "        else:\n",
    "            dfSorted[i] = dfSorted[i].astype('category')\n",
    "        dfSorted[i] = dfSorted[i].cat.codes\n",
    "\n",
    "print(\"Sorted DataFrame Example for 'race':\")\n",
    "print(dfSorted.head())\n",
    "\n",
    "\n",
    "# Select 'race' variable for reordering analysis\n",
    "variable_to_reorder = 'race'\n",
    "\n",
    "# List all categories of the selected variable\n",
    "categories = df[variable_to_reorder].astype('category').cat.categories.tolist()\n",
    "\n",
    "# Generate a subset of possible permutations of the categories for simplicity\n",
    "orderings = list(permutations(categories))[:10]  # Limit to first 10 permutations for simplicity\n",
    "\n",
    "print(f\"\\nInformation Gain for different orderings of '{variable_to_reorder}' categories:\\n\")\n",
    "\n",
    "# Compute information gain for each ordering\n",
    "ig_scores = []\n",
    "for ordering in orderings:\n",
    "    # Define the category type with the current ordering\n",
    "    catType = CategoricalDtype(categories=ordering, ordered=True)\n",
    "    df_sorted = df.copy()\n",
    "    df_sorted[variable_to_reorder] = df_sorted[variable_to_reorder].astype(catType)\n",
    "    df_sorted[variable_to_reorder] = df_sorted[variable_to_reorder].cat.codes\n",
    "    \n",
    "    # Ensure all categorical variables are converted to numerical codes\n",
    "    for col in df_sorted.select_dtypes(include=['category', 'object']).columns:\n",
    "        df_sorted[col] = df_sorted[col].astype('category').cat.codes\n",
    "    \n",
    "    # Compute the information gain with the reordered categories\n",
    "    ig = IG(df_sorted, variable_to_reorder)\n",
    "    ig_scores.append(ig)\n",
    "    print(f\"Ordering: {ordering} -> Information Gain: {ig:.6f}\")\n",
    "\n",
    "# Find the best ordering based on the highest information gain\n",
    "best_ordering_index = np.argmax(ig_scores)\n",
    "best_ordering = orderings[best_ordering_index]\n",
    "\n",
    "print(f\"\\nBest ordering based on information gain: {best_ordering}\")\n",
    "\n",
    "# Apply the best ordering to the original dataframe\n",
    "catType_best = CategoricalDtype(categories=best_ordering, ordered=True)\n",
    "df_best_ordered = df.copy()\n",
    "df_best_ordered[variable_to_reorder] = df_best_ordered[variable_to_reorder].astype(catType_best)\n",
    "df_best_ordered[variable_to_reorder] = df_best_ordered[variable_to_reorder].cat.codes\n",
    "\n",
    "# Ensure all categorical variables are converted to numerical codes in the best ordered dataframe\n",
    "for col in df_best_ordered.select_dtypes(include=['category', 'object']).columns:\n",
    "    df_best_ordered[col] = df_best_ordered[col].astype('category').cat.codes\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_best_ordered.drop('income', axis=1)\n",
    "y = df_best_ordered['income']\n",
    "\n",
    "# Train the decision tree with the best ordering\n",
    "clf_best = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_best.fit(X, y)\n",
    "\n",
    "# Evaluate the decision tree\n",
    "train_accuracy = accuracy_score(y, clf_best.predict(X))\n",
    "print(f\"\\nTraining accuracy with best ordering: {train_accuracy:.2f}\")\n",
    "\n",
    "# Cross-validation to evaluate the decision tree's performance\n",
    "cv_scores = cross_val_score(clf_best, X, y, cv=10)\n",
    "print(f\"Cross-validation accuracy: {cv_scores.mean():.2f} (+/- {cv_scores.std() * 2:.2f})\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification report for the decision tree with best ordering:\")\n",
    "print(classification_report(y, clf_best.predict(X)))\n",
    "\n",
    "# Check the features used by the decision tree\n",
    "features_used = X.columns[clf_best.feature_importances_ > 0]\n",
    "print(\"\\nFeatures used by the decision tree:\")\n",
    "print(features_used)\n",
    "\n",
    "# Best Category Order\n",
    "\n",
    "# Create a new DataFrame to store the reordered dataset\n",
    "df_reordered = df.copy()\n",
    "\n",
    "# Apply the best ordering to the 'race' variable in the new DataFrame\n",
    "df_reordered[variable_to_reorder] = df_reordered[variable_to_reorder].astype(CategoricalDtype(categories=best_ordering, ordered=True))\n",
    "df_reordered[variable_to_reorder] = df_reordered[variable_to_reorder].cat.codes\n",
    "\n",
    "# Ensure all categorical variables are converted to numerical codes in the reordered dataset\n",
    "for col in df_reordered.select_dtypes(include=['category', 'object']).columns:\n",
    "    df_reordered[col] = df_reordered[col].astype('category').cat.codes\n",
    "\n",
    "# Save the new dataset to a CSV file\n",
    "df_reordered.to_csv('../data/adult_reordered.csv', index=False)\n",
    "\n",
    "# Print a message to confirm the dataset has been created and saved\n",
    "print(f\"\\nNew dataset with reordered categories saved as 'adult_reordered.csv' in the 'data' directory.\")\n",
    "\n",
    "# Recompute the classification report for the new dataset with reordered categories\n",
    "\n",
    "# Load the new dataset with reordered categories\n",
    "df_reordered = pd.read_csv('../data/adult_reordered.csv')\n",
    "\n",
    "# Separate the features and target variable for the reordered dataset\n",
    "X_reordered = df_reordered.drop('income', axis=1)\n",
    "y_reordered = df_reordered['income']\n",
    "\n",
    "# Train a new decision tree on the reordered dataset\n",
    "clf_reordered = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_reordered.fit(X_reordered, y_reordered)\n",
    "\n",
    "# Compute the training accuracy for the reordered dataset\n",
    "train_accuracy_reordered = accuracy_score(y_reordered, clf_reordered.predict(X_reordered))\n",
    "print(f\"\\nTraining accuracy with reordered dataset: {train_accuracy_reordered:.2f}\")\n",
    "\n",
    "# Perform cross-validation on the reordered dataset\n",
    "cv_scores_reordered = cross_val_score(clf_reordered, X_reordered, y_reordered, cv=10)\n",
    "print(f\"Cross-validation accuracy for reordered dataset: {cv_scores_reordered.mean():.2f} (+/- {cv_scores_reordered.std() * 2:.2f})\")\n",
    "\n",
    "# Generate the classification report for the reordered dataset\n",
    "print(\"\\nClassification report for the decision tree with reordered dataset:\")\n",
    "classification_report_reordered = classification_report(y_reordered, clf_reordered.predict(X_reordered))\n",
    "print(classification_report_reordered)\n",
    "\n",
    "# Convert all categorical variables in the original dataset to numerical codes\n",
    "df_encoded = df.copy()\n",
    "for col in df_encoded.select_dtypes(include=['category', 'object']).columns:\n",
    "    df_encoded[col] = df_encoded[col].astype('category').cat.codes\n",
    "\n",
    "# Separate the features and target variable for the original dataset\n",
    "X_original = df_encoded.drop('income', axis=1)\n",
    "y_original = df_encoded['income']\n",
    "\n",
    "# Train a new decision tree on the original dataset\n",
    "clf_original = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_original.fit(X_original, y_original)\n",
    "\n",
    "# Compute the training accuracy for the original dataset\n",
    "train_accuracy_original = accuracy_score(y_original, clf_original.predict(X_original))\n",
    "print(f\"\\nTraining accuracy with original dataset: {train_accuracy_original:.2f}\")\n",
    "\n",
    "# Perform cross-validation on the original dataset\n",
    "cv_scores_original = cross_val_score(clf_original, X_original, y_original, cv=10)\n",
    "print(f\"Cross-validation accuracy for original dataset: {cv_scores_original.mean():.2f} (+/- {cv_scores_original.std() * 2:.2f})\")\n",
    "\n",
    "# Generate the classification report for the original dataset\n",
    "print(\"\\nClassification report for the decision tree with original dataset:\")\n",
    "classification_report_original = classification_report(y_original, clf_original.predict(X_original))\n",
    "print(classification_report_original)\n",
    "\n",
    "# Compare the results\n",
    "print(\"\\nComparison between original and reordered datasets:\")\n",
    "print(f\"Training accuracy - Original: {train_accuracy_original:.2f}, Reordered: {train_accuracy_reordered:.2f}\")\n",
    "print(f\"Cross-validation accuracy - Original: {cv_scores_original.mean():.2f} (+/- {cv_scores_original.std() * 2:.2f}), Reordered: {cv_scores_reordered.mean():.2f} (+/- {cv_scores_reordered.std() * 2:.2f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca67fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c09c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b01eb2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for all categorical variables:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Code for exercise 3, task 1 and task 2.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# scikit-learn for decision tree classification and evaluation\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data and make a copy with numerical entries only\n",
    "df = pd.read_csv('../data/adult.csv', na_values='?').dropna()\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "# Ensure 'income' is a categorical variable for our analysis\n",
    "df['income'] = df['income'].astype('category')\n",
    "\n",
    "# Convert other categorical variables to codes for numeric processing\n",
    "datasetnum = df.copy()\n",
    "datasetnum.drop(['education'], axis=1, inplace=True)\n",
    "\n",
    "for i in list(datasetnum):\n",
    "    if not (datasetnum[i].dtype == np.float64 or datasetnum[i].dtype == np.int64):\n",
    "        datasetnum[i] = datasetnum[i].astype('category')\n",
    "        datasetnum[i] = datasetnum[i].cat.codes\n",
    "\n",
    "def IG(df, var):\n",
    "    \"\"\"\n",
    "    Compute information gain for a given dataframe w.r.t. income \n",
    "    when splitting into categorical variable var.\n",
    "    \n",
    "    Return:\n",
    "        float: information gain\n",
    "    \"\"\"\n",
    "    # Entropy before split\n",
    "    entropy1 = df.income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).sum()\n",
    "    print(f\"Entropy before split for {var}: {entropy1:.6f}\")\n",
    "    \n",
    "    # Entropy after split\n",
    "    grouped_entropy = df.groupby([var]).income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).groupby(level=0).sum()\n",
    "    weights = df[var].value_counts(normalize=True)\n",
    "    entropy2 = (grouped_entropy * weights).sum()\n",
    "    print(f\"Grouped entropy for {var}: {grouped_entropy}\")\n",
    "    print(f\"Weights for {var}: {weights}\")\n",
    "    print(f\"Entropy after split for {var}: {entropy2:.6f}\")\n",
    "    \n",
    "    # Return information gain\n",
    "    info_gain = entropy1 - entropy2\n",
    "    return info_gain\n",
    "\n",
    "# List all categorical variables (excluding 'income')\n",
    "categorical_vars = df.select_dtypes(include=['category']).columns.tolist()\n",
    "categorical_vars.remove('income')\n",
    "\n",
    "# Compute and print the information gain for all categorical variables\n",
    "print(\"Information Gain for all categorical variables:\")\n",
    "for var in categorical_vars:\n",
    "    print(f\"\\nProcessing variable: {var}\")\n",
    "    ig = IG(df, var)\n",
    "    print(f\"Information gain for {var}: {ig:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8441821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass   education  education-num      marital-status  \\\n",
       "0       39         State-gov   Bachelors             13       Never-married   \n",
       "1       50  Self-emp-not-inc   Bachelors             13  Married-civ-spouse   \n",
       "2       38           Private     HS-grad              9            Divorced   \n",
       "3       53           Private        11th              7  Married-civ-spouse   \n",
       "4       28           Private   Bachelors             13  Married-civ-spouse   \n",
       "...    ...               ...         ...            ...                 ...   \n",
       "32556   27           Private  Assoc-acdm             12  Married-civ-spouse   \n",
       "32557   40           Private     HS-grad              9  Married-civ-spouse   \n",
       "32558   58           Private     HS-grad              9             Widowed   \n",
       "32559   22           Private     HS-grad              9       Never-married   \n",
       "32560   52      Self-emp-inc     HS-grad              9  Married-civ-spouse   \n",
       "\n",
       "              occupation   relationship   race     sex  capital-gain  \\\n",
       "0           Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1        Exec-managerial        Husband  White    Male             0   \n",
       "2      Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3      Handlers-cleaners        Husband  Black    Male             0   \n",
       "4         Prof-specialty           Wife  Black  Female             0   \n",
       "...                  ...            ...    ...     ...           ...   \n",
       "32556       Tech-support           Wife  White  Female             0   \n",
       "32557  Machine-op-inspct        Husband  White    Male             0   \n",
       "32558       Adm-clerical      Unmarried  White  Female             0   \n",
       "32559       Adm-clerical      Own-child  White    Male             0   \n",
       "32560    Exec-managerial           Wife  White  Female         15024   \n",
       "\n",
       "       capital-loss  hour-per-week native-country income  \n",
       "0                 0             40  United-States  <=50K  \n",
       "1                 0             13  United-States  <=50K  \n",
       "2                 0             40  United-States  <=50K  \n",
       "3                 0             40  United-States  <=50K  \n",
       "4                 0             40           Cuba  <=50K  \n",
       "...             ...            ...            ...    ...  \n",
       "32556             0             38  United-States  <=50K  \n",
       "32557             0             40  United-States   >50K  \n",
       "32558             0             40  United-States  <=50K  \n",
       "32559             0             20  United-States  <=50K  \n",
       "32560             0             40  United-States   >50K  \n",
       "\n",
       "[30162 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7174dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for all categorical variables:\n",
      "Information gain for workclass: 0.017104\n",
      "Information gain for marital-status: 0.157471\n",
      "Information gain for occupation: 0.093194\n",
      "Information gain for relationship: 0.166178\n",
      "Information gain for race: 0.008294\n",
      "Information gain for sex: 0.037406\n",
      "Information gain for native-country: 0.009329\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Code for exercise 3, task 1 and task 2.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# scikit-learn for decision tree classification and evaluation\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data and make a copy with numerical entries only\n",
    "df = pd.read_csv('../data/adult.csv', na_values='?').dropna()\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "# Ensure 'income' is a categorical variable for our analysis\n",
    "df['income'] = df['income'].astype('category')\n",
    "\n",
    "# Explicitly identify and convert categorical columns\n",
    "categorical_columns = [\n",
    "    'workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'\n",
    "]\n",
    "\n",
    "# Convert identified categorical columns to 'category' dtype\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "def IG(df, var):\n",
    "    \"\"\"\n",
    "    Compute information gain for a given dataframe w.r.t. income \n",
    "    when splitting into categorical variable var.\n",
    "    \n",
    "    Return:\n",
    "        float: information gain\n",
    "    \"\"\"\n",
    "    # Entropy before split\n",
    "    entropy1 = df.income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).sum()\n",
    "    \n",
    "    # Entropy after split\n",
    "    grouped_entropy = df.groupby([var]).income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).groupby(level=0).sum()\n",
    "    weights = df[var].value_counts(normalize=True)\n",
    "    entropy2 = (grouped_entropy * weights).sum()\n",
    "    \n",
    "    # Return information gain\n",
    "    info_gain = entropy1 - entropy2\n",
    "    return info_gain\n",
    "\n",
    "# List all categorical variables (excluding 'income')\n",
    "categorical_vars = df.select_dtypes(include=['category']).columns.tolist()\n",
    "categorical_vars.remove('income')\n",
    "\n",
    "# Compute and print the information gain for all categorical variables\n",
    "print(\"Information Gain for all categorical variables:\")\n",
    "for var in categorical_vars:\n",
    "    ig = IG(df, var)\n",
    "    print(f\"Information gain for {var}: {ig:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2e1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3a8f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "157144e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing reorderings for relationship:\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Wife', 'Unmarried') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Unmarried', 'Own-child', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Unmarried', 'Wife', 'Own-child') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Wife', 'Own-child', 'Unmarried') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Wife', 'Unmarried', 'Own-child') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Other-relative', 'Unmarried', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Other-relative', 'Wife', 'Unmarried') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Unmarried', 'Other-relative', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Unmarried', 'Wife', 'Other-relative') -> Information Gain: 0.166178\n",
      "\n",
      "Best ordering for 'relationship': ('Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife') with IG: 0.166178\n",
      "\n",
      "Training accuracy with reordered dataset: 0.98\n",
      "Cross-validation accuracy for reordered dataset: 0.81 (+/- 0.01)\n",
      "\n",
      "Classification report for the decision tree with reordered dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     22654\n",
      "           1       0.98      0.92      0.95      7508\n",
      "\n",
      "    accuracy                           0.98     30162\n",
      "   macro avg       0.98      0.96      0.97     30162\n",
      "weighted avg       0.98      0.98      0.97     30162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Code for exercise 3, task 2 - Improve sorting of 'relationship' and check impact.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data and make a copy with numerical entries only\n",
    "df = pd.read_csv('../data/adult.csv', na_values='?').dropna()\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "# Ensure 'income' is a categorical variable for our analysis\n",
    "df['income'] = df['income'].astype('category')\n",
    "\n",
    "# Identify and convert all categorical columns to codes for numeric processing\n",
    "for col in df.select_dtypes(include=['object', 'category']).columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# Define function to compute information gain\n",
    "def IG(df, var):\n",
    "    entropy1 = df.income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).sum()\n",
    "    grouped_entropy = df.groupby([var]).income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).groupby(level=0).sum()\n",
    "    weights = df[var].value_counts(normalize=True)\n",
    "    entropy2 = (grouped_entropy * weights).sum()\n",
    "    return entropy1 - entropy2\n",
    "\n",
    "# Function to reorder and test new categories for 'relationship'\n",
    "def test_reordering_relationship(df):\n",
    "    var = 'relationship'\n",
    "    categories = df[var].astype('category').cat.categories.tolist()\n",
    "    orderings = list(permutations(categories))\n",
    "    \n",
    "    best_ig = 0\n",
    "    best_ordering = categories\n",
    "    print(f\"\\nTesting reorderings for {var}:\")\n",
    "    \n",
    "    for ordering in orderings[:10]:  # Limit to first 10 permutations for simplicity\n",
    "        cat_type = CategoricalDtype(categories=ordering, ordered=True)\n",
    "        df_reordered = df.copy()\n",
    "        df_reordered[var] = df_reordered[var].astype(cat_type).cat.codes\n",
    "        \n",
    "        ig = IG(df_reordered, var)\n",
    "        print(f\"Ordering: {ordering} -> Information Gain: {ig:.6f}\")\n",
    "        \n",
    "        if ig > best_ig:\n",
    "            best_ig = ig\n",
    "            best_ordering = ordering\n",
    "    \n",
    "    return best_ordering, best_ig\n",
    "\n",
    "# Test reorderings for 'relationship'\n",
    "best_ordering_relationship, best_ig_relationship = test_reordering_relationship(df)\n",
    "\n",
    "print(f\"\\nBest ordering for 'relationship': {best_ordering_relationship} with IG: {best_ig_relationship:.6f}\")\n",
    "\n",
    "# Apply the best ordering to create a new dataset\n",
    "df_reordered = df.copy()\n",
    "df_reordered['relationship'] = df_reordered['relationship'].astype(CategoricalDtype(categories=best_ordering_relationship, ordered=True)).cat.codes\n",
    "\n",
    "# Convert all categorical variables to numeric codes in the reordered dataset\n",
    "for col in df_reordered.select_dtypes(include=['category']).columns:\n",
    "    df_reordered[col] = df_reordered[col].cat.codes\n",
    "\n",
    "# Prepare data for training and evaluation\n",
    "X_reordered = df_reordered.drop('income', axis=1)\n",
    "y_reordered = df_reordered['income']\n",
    "\n",
    "# Train a decision tree on the reordered dataset\n",
    "clf_reordered = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_reordered.fit(X_reordered, y_reordered)\n",
    "\n",
    "# Training and cross-validation accuracy\n",
    "train_accuracy_reordered = accuracy_score(y_reordered, clf_reordered.predict(X_reordered))\n",
    "cv_scores_reordered = cross_val_score(clf_reordered, X_reordered, y_reordered, cv=10)\n",
    "\n",
    "print(f\"\\nTraining accuracy with reordered dataset: {train_accuracy_reordered:.2f}\")\n",
    "print(f\"Cross-validation accuracy for reordered dataset: {cv_scores_reordered.mean():.2f} (+/- {cv_scores_reordered.std() * 2:.2f})\")\n",
    "\n",
    "# Classification report for the reordered dataset\n",
    "print(\"\\nClassification report for the decision tree with reordered dataset:\")\n",
    "classification_report_reordered = classification_report(y_reordered, clf_reordered.predict(X_reordered))\n",
    "print(classification_report_reordered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0434723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4a9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a0023f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for all categorical variables:\n",
      "\n",
      "Testing reorderings for relationship:\n",
      "Ordering: (0, 1, 2, 3, 4, 5) -> Information Gain: 0.166178\n",
      "Ordering: (0, 1, 2, 3, 5, 4) -> Information Gain: 0.166178\n",
      "Ordering: (0, 1, 2, 4, 3, 5) -> Information Gain: 0.166178\n",
      "Ordering: (0, 1, 2, 4, 5, 3) -> Information Gain: 0.166178\n",
      "Ordering: (0, 1, 2, 5, 3, 4) -> Information Gain: 0.166178\n",
      "Ordering: (0, 1, 2, 5, 4, 3) -> Information Gain: 0.166178\n",
      "Ordering: (0, 1, 3, 2, 4, 5) -> Information Gain: 0.166178\n",
      "Ordering: (0, 1, 3, 2, 5, 4) -> Information Gain: 0.166178\n",
      "Ordering: (0, 1, 3, 4, 2, 5) -> Information Gain: 0.166178\n",
      "Ordering: (0, 1, 3, 4, 5, 2) -> Information Gain: 0.166178\n",
      "\n",
      "Best ordering for 'relationship': (0, 1, 2, 3, 4, 5) with IG: 0.166178\n",
      "\n",
      "Training accuracy with reordered dataset: 0.98\n",
      "Cross-validation accuracy for reordered dataset: 0.81 (+/- 0.01)\n",
      "\n",
      "Classification report for the decision tree with reordered dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     22654\n",
      "           1       0.98      0.92      0.95      7508\n",
      "\n",
      "    accuracy                           0.98     30162\n",
      "   macro avg       0.98      0.96      0.97     30162\n",
      "weighted avg       0.98      0.98      0.97     30162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Code for exercise 3, task 1 and task 2.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# scikit-learn for decision tree classification and evaluation\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data and make a copy with numerical entries only\n",
    "df = pd.read_csv('../data/adult.csv', na_values='?').dropna()\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "# Ensure 'income' is a categorical variable for our analysis\n",
    "df['income'] = df['income'].astype('category')\n",
    "\n",
    "# Explicitly identify and convert categorical columns\n",
    "categorical_columns = [\n",
    "    'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'\n",
    "]\n",
    "\n",
    "# Convert identified categorical columns to 'category' dtype and then to numeric codes\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "    df[col] = df[col].cat.codes\n",
    "\n",
    "def IG(df, var):\n",
    "    \"\"\"\n",
    "    Compute information gain for a given dataframe w.r.t. income \n",
    "    when splitting into categorical variable var.\n",
    "    \n",
    "    Return:\n",
    "        float: information gain\n",
    "    \"\"\"\n",
    "    # Entropy before split\n",
    "    entropy1 = df.income.value_counts(normalize=True).apply(lambda x: -x * np.log2(x)).sum()\n",
    "    \n",
    "    # Entropy after split\n",
    "    grouped_entropy = df.groupby([var]).income.value_counts(normalize=True).apply(lambda x: -x * np.log2(x)).groupby(level=0).sum()\n",
    "    weights = df[var].value_counts(normalize=True)\n",
    "    entropy2 = (grouped_entropy * weights).sum()\n",
    "    \n",
    "    # Return information gain\n",
    "    return entropy1 - entropy2\n",
    "\n",
    "# List all categorical variables (excluding 'income')\n",
    "categorical_vars = df.select_dtypes(include=['category']).columns.tolist()\n",
    "categorical_vars.remove('income')\n",
    "\n",
    "# Compute and print the information gain for all categorical variables\n",
    "print(\"Information Gain for all categorical variables:\")\n",
    "for var in categorical_vars:\n",
    "    ig = IG(df, var)\n",
    "    print(f\"Information gain for {var}: {ig:.6f}\")\n",
    "\n",
    "# Function to reorder and test new categories for 'relationship'\n",
    "def test_reordering_relationship(df):\n",
    "    var = 'relationship'\n",
    "    categories = df[var].astype('category').cat.categories.tolist()\n",
    "    orderings = list(permutations(categories))\n",
    "    \n",
    "    best_ig = 0\n",
    "    best_ordering = categories\n",
    "    print(f\"\\nTesting reorderings for {var}:\")\n",
    "    \n",
    "    for ordering in orderings[:10]:  # Limit to first 10 permutations for simplicity\n",
    "        cat_type = CategoricalDtype(categories=ordering, ordered=True)\n",
    "        df_reordered = df.copy()\n",
    "        df_reordered[var] = df_reordered[var].astype(cat_type).cat.codes\n",
    "        \n",
    "        ig = IG(df_reordered, var)\n",
    "        print(f\"Ordering: {ordering} -> Information Gain: {ig:.6f}\")\n",
    "        \n",
    "        if ig > best_ig:\n",
    "            best_ig = ig\n",
    "            best_ordering = ordering\n",
    "    \n",
    "    return best_ordering, best_ig\n",
    "\n",
    "# Test reorderings for 'relationship'\n",
    "best_ordering_relationship, best_ig_relationship = test_reordering_relationship(df)\n",
    "\n",
    "print(f\"\\nBest ordering for 'relationship': {best_ordering_relationship} with IG: {best_ig_relationship:.6f}\")\n",
    "\n",
    "# Apply the best ordering to create a new dataset\n",
    "df_reordered = df.copy()\n",
    "df_reordered['relationship'] = df_reordered['relationship'].astype(CategoricalDtype(categories=best_ordering_relationship, ordered=True)).cat.codes\n",
    "\n",
    "# Convert all categorical variables to numeric codes in the reordered dataset\n",
    "for col in df_reordered.select_dtypes(include=['category']).columns:\n",
    "    df_reordered[col] = df_reordered[col].cat.codes\n",
    "\n",
    "# Prepare data for training and evaluation\n",
    "X_reordered = df_reordered.drop('income', axis=1)\n",
    "y_reordered = df_reordered['income']\n",
    "\n",
    "# Train a decision tree on the reordered dataset\n",
    "clf_reordered = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_reordered.fit(X_reordered, y_reordered)\n",
    "\n",
    "# Training and cross-validation accuracy\n",
    "train_accuracy_reordered = accuracy_score(y_reordered, clf_reordered.predict(X_reordered))\n",
    "cv_scores_reordered = cross_val_score(clf_reordered, X_reordered, y_reordered, cv=10)\n",
    "\n",
    "print(f\"\\nTraining accuracy with reordered dataset: {train_accuracy_reordered:.2f}\")\n",
    "print(f\"Cross-validation accuracy for reordered dataset: {cv_scores_reordered.mean():.2f} (+/- {cv_scores_reordered.std() * 2:.2f})\")\n",
    "\n",
    "# Classification report for the reordered dataset\n",
    "print(\"\\nClassification report for the decision tree with reordered dataset:\")\n",
    "classification_report_reordered = classification_report(y_reordered, clf_reordered.predict(X_reordered))\n",
    "print(classification_report_reordered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df170df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31e9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c139a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b107a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for all categorical variables:\n",
      "Information gain for workclass: 0.017104\n",
      "Information gain for education: 0.093394\n",
      "Information gain for marital-status: 0.157471\n",
      "Information gain for occupation: 0.093194\n",
      "Information gain for relationship: 0.166178\n",
      "Information gain for race: 0.008294\n",
      "Information gain for sex: 0.037406\n",
      "Information gain for native-country: 0.009329\n",
      "\n",
      "Testing reorderings for relationship:\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Wife', 'Unmarried') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Unmarried', 'Own-child', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Unmarried', 'Wife', 'Own-child') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Wife', 'Own-child', 'Unmarried') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Wife', 'Unmarried', 'Own-child') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Other-relative', 'Unmarried', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Other-relative', 'Wife', 'Unmarried') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Unmarried', 'Other-relative', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Unmarried', 'Wife', 'Other-relative') -> Information Gain: 0.166178\n",
      "\n",
      "Training accuracy with reordered dataset: 0.98\n",
      "Cross-validation accuracy for reordered dataset: 0.81 (+/- 0.01)\n",
      "\n",
      "Classification report for the decision tree with reordered dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     22654\n",
      "           1       0.98      0.92      0.95      7508\n",
      "\n",
      "    accuracy                           0.98     30162\n",
      "   macro avg       0.98      0.96      0.97     30162\n",
      "weighted avg       0.98      0.98      0.97     30162\n",
      "\n",
      "\n",
      "Reordered dataset saved as 'adult_reordered.csv' in the 'data' directory.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Code for exercise 3, task 1 and task 2.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# scikit-learn for decision tree classification and evaluation\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data and make a copy with numerical entries only\n",
    "df = pd.read_csv('../data/adult.csv', na_values='?').dropna()\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "# Identify and convert all categorical columns to codes for numeric processing\n",
    "for col in df.select_dtypes(include=['object', 'category']).columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# Explicitly identify and convert categorical columns\n",
    "categorical_columns = [\n",
    "    'workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'\n",
    "]\n",
    "\n",
    "# Convert identified categorical columns to 'category' dtype\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "def IG(df, var):\n",
    "    \"\"\"\n",
    "    Compute information gain for a given dataframe w.r.t. income \n",
    "    when splitting into categorical variable var.\n",
    "    \n",
    "    Return:\n",
    "        float: information gain\n",
    "    \"\"\"\n",
    "    # Entropy before split\n",
    "    entropy1 = df.income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).sum()\n",
    "    \n",
    "    # Entropy after split\n",
    "    grouped_entropy = df.groupby([var]).income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).groupby(level=0).sum()\n",
    "    weights = df[var].value_counts(normalize=True)\n",
    "    entropy2 = (grouped_entropy * weights).sum()\n",
    "    \n",
    "    # Return information gain\n",
    "    info_gain = entropy1 - entropy2\n",
    "    return info_gain\n",
    "\n",
    "# List all categorical variables (excluding 'income')\n",
    "categorical_vars = df.select_dtypes(include=['category']).columns.tolist()\n",
    "categorical_vars.remove('income')\n",
    "\n",
    "# Compute and print the information gain for all categorical variables\n",
    "print(\"Information Gain for all categorical variables:\")\n",
    "for var in categorical_vars:\n",
    "    ig = IG(df, var)\n",
    "    print(f\"Information gain for {var}: {ig:.6f}\")\n",
    "\n",
    "\n",
    "# Function to reorder and test new categories for 'relationship'\n",
    "def test_reordering_relationship(df):\n",
    "    var = 'relationship'\n",
    "    categories = df[var].astype('category').cat.categories.tolist()\n",
    "    orderings = list(permutations(categories))\n",
    "    \n",
    "    best_ig = 0\n",
    "    best_ordering = categories\n",
    "    print(f\"\\nTesting reorderings for {var}:\")\n",
    "    \n",
    "    for ordering in orderings[:10]:  # Limit to first 10 permutations for simplicity\n",
    "        cat_type = CategoricalDtype(categories=ordering, ordered=True)\n",
    "        df_reordered = df.copy()\n",
    "        df_reordered[var] = df_reordered[var].astype(cat_type).cat.codes\n",
    "        \n",
    "        ig = IG(df_reordered, var)\n",
    "        print(f\"Ordering: {ordering} -> Information Gain: {ig:.6f}\")\n",
    "        \n",
    "        if ig > best_ig:\n",
    "            best_ig = ig\n",
    "            best_ordering = ordering\n",
    "    \n",
    "    return best_ordering, best_ig\n",
    "\n",
    "# Test reorderings for 'relationship'\n",
    "best_ordering_relationship, best_ig_relationship = test_reordering_relationship(df)\n",
    "\n",
    "\n",
    "# Apply the best ordering to create a new dataset\n",
    "df_reordered = df.copy()\n",
    "df_reordered['relationship'] = df_reordered['relationship'].astype(CategoricalDtype(categories=best_ordering_relationship, ordered=True)).cat.codes\n",
    "\n",
    "# Convert all categorical variables to numeric codes in the reordered dataset\n",
    "for col in df_reordered.select_dtypes(include=['category']).columns:\n",
    "    df_reordered[col] = df_reordered[col].cat.codes\n",
    "\n",
    "# Prepare data for training and evaluation\n",
    "X_reordered = df_reordered.drop('income', axis=1)\n",
    "y_reordered = df_reordered['income']\n",
    "\n",
    "# Train a decision tree on the reordered dataset\n",
    "clf_reordered = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_reordered.fit(X_reordered, y_reordered)\n",
    "\n",
    "# Training and cross-validation accuracy\n",
    "train_accuracy_reordered = accuracy_score(y_reordered, clf_reordered.predict(X_reordered))\n",
    "cv_scores_reordered = cross_val_score(clf_reordered, X_reordered, y_reordered, cv=10)\n",
    "\n",
    "print(f\"\\nTraining accuracy with reordered dataset: {train_accuracy_reordered:.2f}\")\n",
    "print(f\"Cross-validation accuracy for reordered dataset: {cv_scores_reordered.mean():.2f} (+/- {cv_scores_reordered.std() * 2:.2f})\")\n",
    "\n",
    "# Classification report for the reordered dataset\n",
    "print(\"\\nClassification report for the decision tree with reordered dataset:\")\n",
    "classification_report_reordered = classification_report(y_reordered, clf_reordered.predict(X_reordered))\n",
    "print(classification_report_reordered)\n",
    "\n",
    "# Save the new dataset to a CSV file\n",
    "df_reordered.to_csv('../data/adult_reordered.csv', index=False)\n",
    "print(\"\\nReordered dataset saved as 'adult_reordered.csv' in the 'data' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37297f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031508ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad655a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for all categorical variables:\n",
      "Information gain for workclass: 0.017104\n",
      "Information gain for marital-status: 0.157471\n",
      "Information gain for occupation: 0.093194\n",
      "Information gain for relationship: 0.166178\n",
      "Information gain for race: 0.008294\n",
      "Information gain for sex: 0.037406\n",
      "Information gain for native-country: 0.009329\n",
      "\n",
      "Testing reorderings for relationship:\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Wife', 'Unmarried') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Unmarried', 'Own-child', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Unmarried', 'Wife', 'Own-child') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Wife', 'Own-child', 'Unmarried') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Other-relative', 'Wife', 'Unmarried', 'Own-child') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Other-relative', 'Unmarried', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Other-relative', 'Wife', 'Unmarried') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Unmarried', 'Other-relative', 'Wife') -> Information Gain: 0.166178\n",
      "Ordering: ('Husband', 'Not-in-family', 'Own-child', 'Unmarried', 'Wife', 'Other-relative') -> Information Gain: 0.166178\n",
      "\n",
      "Best ordering for 'relationship': ('Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife') with IG: 0.166178\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Bachelors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 103\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Train a decision tree on the reordered dataset\u001b[39;00m\n\u001b[0;32m    102\u001b[0m clf_reordered \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mDecisionTreeClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mclf_reordered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_reordered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_reordered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Training and cross-validation accuracy\u001b[39;00m\n\u001b[0;32m    106\u001b[0m train_accuracy_reordered \u001b[38;5;241m=\u001b[39m accuracy_score(y_reordered, clf_reordered\u001b[38;5;241m.\u001b[39mpredict(X_reordered))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:252\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    248\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    249\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    250\u001b[0m )\n\u001b[0;32m    251\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 252\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m missing_values_in_feature_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_missing_values_in_feature_mask(X)\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:645\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_X_params:\n\u001b[0;32m    644\u001b[0m     check_X_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params}\n\u001b[1;32m--> 645\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params)\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[0;32m    647\u001b[0m     check_y_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params}\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Bachelors'"
     ]
    }
   ],
   "source": [
    "\"\"\"Code for exercise 3, task 1 and task 2.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# scikit-learn for decision tree classification and evaluation\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data and make a copy with numerical entries only\n",
    "df = pd.read_csv('../data/adult.csv', na_values='?').dropna()\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "# Ensure 'income' is a categorical variable for our analysis\n",
    "df['income'] = df['income'].astype('category')\n",
    "\n",
    "# Explicitly identify and convert categorical columns\n",
    "categorical_columns = [\n",
    "    'workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'\n",
    "]\n",
    "\n",
    "# Convert identified categorical columns to 'category' dtype\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "def IG(df, var):\n",
    "    \"\"\"\n",
    "    Compute information gain for a given dataframe w.r.t. income \n",
    "    when splitting into categorical variable var.\n",
    "    \n",
    "    Return:\n",
    "        float: information gain\n",
    "    \"\"\"\n",
    "    # Entropy before split\n",
    "    entropy1 = df.income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).sum()\n",
    "    \n",
    "    # Entropy after split\n",
    "    grouped_entropy = df.groupby([var]).income.value_counts(normalize=True).apply(lambda x: -x*np.log2(x)).groupby(level=0).sum()\n",
    "    weights = df[var].value_counts(normalize=True)\n",
    "    entropy2 = (grouped_entropy * weights).sum()\n",
    "    \n",
    "    # Return information gain\n",
    "    info_gain = entropy1 - entropy2\n",
    "    return info_gain\n",
    "\n",
    "# List all categorical variables (excluding 'income')\n",
    "categorical_vars = df.select_dtypes(include=['category']).columns.tolist()\n",
    "categorical_vars.remove('income')\n",
    "\n",
    "# Compute and print the information gain for all categorical variables\n",
    "print(\"Information Gain for all categorical variables:\")\n",
    "for var in categorical_vars:\n",
    "    ig = IG(df, var)\n",
    "    print(f\"Information gain for {var}: {ig:.6f}\")\n",
    "\n",
    "\n",
    "# Function to reorder and test new categories for 'relationship'\n",
    "def test_reordering_relationship(df):\n",
    "    var = 'relationship'\n",
    "    categories = df[var].astype('category').cat.categories.tolist()\n",
    "    orderings = list(permutations(categories))\n",
    "    \n",
    "    best_ig = 0\n",
    "    best_ordering = categories\n",
    "    print(f\"\\nTesting reorderings for {var}:\")\n",
    "    \n",
    "    for ordering in orderings[:10]:  # Limit to first 10 permutations for simplicity\n",
    "        cat_type = CategoricalDtype(categories=ordering, ordered=True)\n",
    "        df_reordered = df.copy()\n",
    "        df_reordered[var] = df_reordered[var].astype(cat_type).cat.codes\n",
    "        \n",
    "        ig = IG(df_reordered, var)\n",
    "        print(f\"Ordering: {ordering} -> Information Gain: {ig:.6f}\")\n",
    "        \n",
    "        if ig > best_ig:\n",
    "            best_ig = ig\n",
    "            best_ordering = ordering\n",
    "    \n",
    "    return best_ordering, best_ig\n",
    "\n",
    "# Test reorderings for 'relationship'\n",
    "best_ordering_relationship, best_ig_relationship = test_reordering_relationship(df)\n",
    "\n",
    "print(f\"\\nBest ordering for 'relationship': {best_ordering_relationship} with IG: {best_ig_relationship:.6f}\")\n",
    "\n",
    "# Apply the best ordering to create a new dataset\n",
    "df_reordered = df.copy()\n",
    "df_reordered['relationship'] = df_reordered['relationship'].astype(CategoricalDtype(categories=best_ordering_relationship, ordered=True)).cat.codes\n",
    "\n",
    "# Convert all categorical variables to numeric codes in the reordered dataset\n",
    "for col in df_reordered.select_dtypes(include=['category']).columns:\n",
    "    df_reordered[col] = df_reordered[col].cat.codes\n",
    "\n",
    "# Prepare data for training and evaluation\n",
    "X_reordered = df_reordered.drop('income', axis=1)\n",
    "y_reordered = df_reordered['income']\n",
    "\n",
    "# Train a decision tree on the reordered dataset\n",
    "clf_reordered = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_reordered.fit(X_reordered, y_reordered)\n",
    "\n",
    "# Training and cross-validation accuracy\n",
    "train_accuracy_reordered = accuracy_score(y_reordered, clf_reordered.predict(X_reordered))\n",
    "cv_scores_reordered = cross_val_score(clf_reordered, X_reordered, y_reordered, cv=10)\n",
    "\n",
    "print(f\"\\nTraining accuracy with reordered dataset: {train_accuracy_reordered:.2f}\")\n",
    "print(f\"Cross-validation accuracy for reordered dataset: {cv_scores_reordered.mean():.2f} (+/- {cv_scores_reordered.std() * 2:.2f})\")\n",
    "\n",
    "# Classification report for the reordered dataset\n",
    "print(\"\\nClassification report for the decision tree with reordered dataset:\")\n",
    "classification_report_reordered = classification_report(y_reordered, clf_reordered.predict(X_reordered))\n",
    "print(classification_report_reordered)\n",
    "\n",
    "# Save the new dataset to a CSV file\n",
    "df_reordered.to_csv('../data/adult_reordered.csv', index=False)\n",
    "print(\"\\nReordered dataset saved as 'adult_reordered.csv' in the 'data' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e16f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03f5df05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Preschool</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1st-4th</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5th-6th</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        education  education-num\n",
       "224     Preschool              1\n",
       "416       1st-4th              2\n",
       "56        5th-6th              3\n",
       "15        7th-8th              4\n",
       "6             9th              5\n",
       "219          10th              6\n",
       "3            11th              7\n",
       "415          12th              8\n",
       "2         HS-grad              9\n",
       "10   Some-college             10\n",
       "48      Assoc-voc             11\n",
       "13     Assoc-acdm             12\n",
       "0       Bachelors             13\n",
       "5         Masters             14\n",
       "52    Prof-school             15\n",
       "20      Doctorate             16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py:78\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m         proc \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\subprocess.py:1436\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1436\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1438\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m rawdot \u001b[38;5;241m=\u001b[39m rawdot[:\u001b[38;5;241m15\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph [size=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m];\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m rawdot[\u001b[38;5;241m15\u001b[39m:]\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# render the tree\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m display(\u001b[43mgraphviz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawdot\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../E3-figures/decisionTree_manual\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03mdisplay(graphviz.Source(digraph Tree {\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03mnode [shape=box];\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m}).render('E3-figures/decisionTree_manual', format='png')\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[0;32m    118\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(filename, directory\u001b[38;5;241m=\u001b[39mdirectory, skip_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(filepath)\n\u001b[1;32m--> 122\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[0;32m    125\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, filepath)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\rendering.py:326\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[0;32m    322\u001b[0m cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork around pytype false alarm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 326\u001b[0m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mfspath(outfile)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "\"\"\"Code for exercise 3, task 3.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# graphviz for tree drawing\n",
    "import graphviz\n",
    "\n",
    "# scikit-learn for decision tree classification and evaluation\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# load the data and make a copy with numerical entries only\n",
    "df = pd.read_csv('../data/adult.csv', na_values='?').dropna()\n",
    "\n",
    "# print the code for the education\n",
    "display(df[['education', 'education-num']].drop_duplicates().sort_values(['education-num']))\n",
    "\n",
    "df.drop(['fnlwgt', 'education'], axis=1, inplace=True)\n",
    "\n",
    "for i in list(df):\n",
    "    if not (df[i].dtype == np.float64 or df[i].dtype == np.int64):\n",
    "        # define a specific order for race\n",
    "        if 'race' in i:\n",
    "            cat_type = CategoricalDtype(categories=[\n",
    "              'Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'], ordered=True)\n",
    "            df[i] = df[i].astype(cat_type)\n",
    "        else:\n",
    "            df[i] = df[i].astype('category')\n",
    "        df[i] = df[i].cat.codes\n",
    "        \n",
    "# select the data\n",
    "datasub = df\n",
    "# you can descend in the tree by selecting respective data\n",
    "#datasub = df[df.relationship >1]\n",
    "X = datasub.iloc[:,0:-1]\n",
    "Y = datasub.iloc[:,-1]\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\", max_leaf_nodes=20)\n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "# compute dot layout of tree\n",
    "rawdot = export_graphviz(clf, out_file=None, feature_names=X.columns, \n",
    "                         class_names=['<=50k', '>50k'], filled=True)#, proportion=True)\n",
    "# scale the nodes\n",
    "rawdot = rawdot[:15] + 'graph [size=\"10\"];' + rawdot[15:]\n",
    "\n",
    "# render the tree\n",
    "display(graphviz.Source(rawdot).render('../E3-figures/decisionTree_manual', format='png'))\n",
    "\n",
    "'''\n",
    "display(graphviz.Source(digraph Tree {\n",
    "node [shape=box];\n",
    "graph [ranksep=.75, size=\"7 3\"];\n",
    "0 [label=\"Do you intend\\n to get married?\"];\n",
    "1 [label=\"Will you go\\n to college?\", style=filled, fillcolor=\"red\"]; 0 -> 1 [labeldistance=3, labelangle=45, headlabel=\"yes\"];\n",
    "2 [label=\"Your capital gain:\"]; 0 -> 2 [labeldistance=3, labelangle=-45, headlabel=\"no\"];\n",
    "3 [label=\"?\", style=filled, fillcolor=\"red\"]; 2 -> 3 [labeldistance=3, labelangle=45, headlabel=\"<=7000\"];\n",
    "6 [label=\"Your chances\\n are high!\", style=filled, fillcolor=\"green\"]; 2 -> 6 [labeldistance=3, labelangle=-45, headlabel=\">7000\"];\n",
    "}).render('E3-figures/decisionTree_manual', format='png')\n",
    "'''\n",
    "# write to file: graphviz.Source(...).render('E3-figures/decisionTree_manual',format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a64a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
